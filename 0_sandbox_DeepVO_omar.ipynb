{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa60944-1d5c-4667-a6ab-65d1865beb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" REFERENCES\n",
    "https://github.com/ChiWeiHsiao/DeepVO-pytorch\n",
    "\n",
    "Original pipeline:\n",
    "\n",
    "- Download data\n",
    "- Preprocessing\n",
    "- Load pretrained model\n",
    "- Change hyperparams\n",
    "- Train (run main)\n",
    "- Evaluate (run test\n",
    "- Visualise results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff60aa2-d5df-4a8e-b90c-887ab90ef1bc",
   "metadata": {},
   "source": [
    "# Data Download\n",
    "\n",
    "Already downloaded from the AISG-SLA website, located in `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2effdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [0, 1398]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from params import par\n",
    "import pandas as pd\n",
    "\n",
    "# Get the start and end indices for each sequence from the \"train_labels.csv\" file\n",
    "def get_sequence_ranges():\n",
    "    data = pd.read_csv(os.path.join(par.data_dir, 'train_labels.csv'))\n",
    "    data['Timestamp'] = pd.to_datetime(data['Timestamp'])  # Convert column from \"Timestamp\" to type datetime\n",
    "\n",
    "    # Filter only the rows corresponding to image files\n",
    "    data = data[data['Filename'].str.endswith('.jpg')]\n",
    "\n",
    "    # Sort data by\"Timestamp\"\n",
    "    data = data.sort_values(by='Timestamp')\n",
    "\n",
    "    sequence_ranges = {}  # Dictionary to store start and end indices for each sequence\n",
    "\n",
    "    for trajectory_id, group in data.groupby('TrajectoryId'):\n",
    "        indices = group.index.values  # Get the indices of the rows corresponding to this sequence\n",
    "        sequence_ranges[trajectory_id] = [min(indices), max(indices)]\n",
    "\n",
    "    return sequence_ranges\n",
    "\n",
    "# Get the dictionary of sequences and their ranges\n",
    "sequence_ranges_dict = get_sequence_ranges()\n",
    "\n",
    "# Print dict\n",
    "print(sequence_ranges_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201113c-7a08-46f9-ace4-2460999a65c2",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f230103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import time\n",
    "from helper import R_to_angle\n",
    "from params import par\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import math\n",
    "\n",
    "\n",
    "# transform poseGT [R|t] to [theta_x, theta_y, theta_z, x, y, z]\n",
    "# save as .npy file\n",
    "def create_pose_data():\n",
    "    sequence_ranges = get_sequence_ranges()\n",
    "    start_t = time.time()\n",
    "    for trajectory_id, indices in sequence_ranges.items():\n",
    "        fn = os.path.join(par.pose_dir, '{:02d}.txt'.format(trajectory_id))\n",
    "        print('Transforming {}...'.format(fn))\n",
    "\n",
    "        # Leer los datos de poses desde el archivo CSV\n",
    "        data = pd.read_csv(os.path.join(par.data_dir, 'train_labels.csv'))\n",
    "        pose_data = data[data['TrajectoryId'] == trajectory_id][['Easting', 'Northing', 'Height', 'Roll', 'Pitch', 'Yaw']].values\n",
    "\n",
    "        # Normalizar los datos de poses\n",
    "        pose_data[:, :3] = pose_data[:, :3] - pose_data[:, :3].mean(axis=0)\n",
    "        pose_data[:, 3:] = pose_data[:, 3:] - pose_data[:, 3:].mean(axis=0)\n",
    "\n",
    "        # Procesar los datos de poses y guardarlos como un archivo .npy\n",
    "        np.save(os.path.join(par.data_dir, 'pose_GT', 'poses_{}.npy'.format(trajectory_id)), pose_data)\n",
    "\n",
    "        print('Trajectory {}: shape={}'.format(trajectory_id, pose_data.shape))\n",
    "    print('elapsed time = {}'.format(time.time() - start_t))\n",
    "\n",
    "def calculate_rgb_mean_std(image_path_list, minus_point_5=False):\n",
    "    n_images = len(image_path_list)\n",
    "    cnt_pixels = 0\n",
    "    print('Numbers of frames in training dataset: {}'.format(n_images))\n",
    "    mean_np = [0, 0, 0]\n",
    "    mean_tensor = [0, 0, 0]\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    image_sequence = []\n",
    "    for idx, img_path in enumerate(image_path_list):\n",
    "        print('{} / {}'.format(idx, n_images), end='\\r')\n",
    "        img_as_img = Image.open(img_path)\n",
    "        img_as_tensor = to_tensor(img_as_img)\n",
    "        if minus_point_5:\n",
    "            img_as_tensor = img_as_tensor - 0.5\n",
    "        img_as_np = np.array(img_as_img)\n",
    "        img_as_np = np.rollaxis(img_as_np, 2, 0)\n",
    "        cnt_pixels += img_as_np.shape[1]*img_as_np.shape[2]\n",
    "        for c in range(3):\n",
    "            mean_tensor[c] += float(torch.sum(img_as_tensor[c]))\n",
    "            mean_np[c] += float(np.sum(img_as_np[c]))\n",
    "    mean_tensor =  [v / cnt_pixels for v in mean_tensor]\n",
    "    mean_np = [v / cnt_pixels for v in mean_np]\n",
    "    print('mean_tensor = ', mean_tensor)\n",
    "    print('mean_np = ', mean_np)\n",
    "\n",
    "    std_tensor = [0, 0, 0]\n",
    "    std_np = [0, 0, 0]\n",
    "    for idx, img_path in enumerate(image_path_list):\n",
    "        print('{} / {}'.format(idx, n_images), end='\\r')\n",
    "        img_as_img = Image.open(img_path)\n",
    "        img_as_tensor = to_tensor(img_as_img)\n",
    "        if minus_point_5:\n",
    "            img_as_tensor = img_as_tensor - 0.5\n",
    "        img_as_np = np.array(img_as_img)\n",
    "        img_as_np = np.rollaxis(img_as_np, 2, 0)\n",
    "        for c in range(3):\n",
    "            tmp = (img_as_tensor[c] - mean_tensor[c])**2\n",
    "            std_tensor[c] += float(torch.sum(tmp))\n",
    "            tmp = (img_as_np[c] - mean_np[c])**2\n",
    "            std_np[c] += float(np.sum(tmp))\n",
    "    std_tensor = [math.sqrt(v / cnt_pixels) for v in std_tensor]\n",
    "    std_np = [math.sqrt(v / cnt_pixels) for v in std_np]\n",
    "    print('std_tensor = ', std_tensor)\n",
    "    print('std_np = ', std_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b458d87-4dc9-4832-8894-bebc7d2a4f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming C:/Users/Omar/Documents/Tarecda/aisg-sla/data//pose_GT/01.txt...\n",
      "Trajectory 1: shape=(1399, 6)\n",
      "elapsed time = 0.009997844696044922\n",
      "Numbers of frames in training dataset: 1399\n",
      "mean_tensor =  [0.051340546093462204, 0.058663660712425306, 0.036986723011486415]\n",
      "mean_np =  [140.59183676930283, 142.45923109812955, 136.93161197517873]\n",
      "std_tensor =  [0.26167191129873923, 0.26125147532781323, 0.30125377150941884]\n",
      "std_np =  [66.72633676808925, 66.61912628967855, 76.81971117246313]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_video = par.train_video\n",
    "    image_path_list = []\n",
    "    # Calculate RGB means of images in training videos\n",
    "    for folder in train_video:\n",
    "        image_path_list += glob.glob(os.path.join(par.image_dir, str(folder), '*.jpg'))\n",
    "    create_pose_data() # Normalizar los datos de poses\n",
    "    calculate_rgb_mean_std(image_path_list, minus_point_5=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from params import par\n",
    "from model import DeepVO\n",
    "from data_helper import get_data_info, SortedRandomBatchSampler, ImageSequenceDataset, get_partition_data_info\n",
    "\n",
    "\n",
    "# Write all hyperparameters to record_path\n",
    "mode = 'a' if par.resume else 'w'\n",
    "with open(par.record_path, mode) as f:\n",
    "    f.write('\\n'+'='*50 + '\\n')\n",
    "    f.write('\\n'.join(\"%s: %s\" % item for item in vars(par).items()))\n",
    "    f.write('\\n'+'='*50 + '\\n')\n",
    "\n",
    "# Prepare Data\n",
    "if os.path.isfile(par.train_data_info_path) and os.path.isfile(par.valid_data_info_path):\n",
    "    print('Load data info from {}'.format(par.train_data_info_path))\n",
    "    train_df = pd.read_pickle(par.train_data_info_path)\n",
    "    valid_df = pd.read_pickle(par.valid_data_info_path)\n",
    "else:\n",
    "    print('Create new data info')\n",
    "    if par.partition != None:\n",
    "        partition = par.partition\n",
    "        train_df, valid_df = get_partition_data_info(partition, par.train_video, par.seq_len, overlap=1, sample_times=par.sample_times, shuffle=True, sort=True)\n",
    "    else:\n",
    "        train_df = get_data_info(folder_list=par.train_video, seq_len_range=par.seq_len, overlap=1, sample_times=par.sample_times)\n",
    "        valid_df = get_data_info(folder_list=par.valid_video, seq_len_range=par.seq_len, overlap=1, sample_times=par.sample_times)\n",
    "    # save the data info\n",
    "    train_df.to_pickle(par.train_data_info_path)\n",
    "    valid_df.to_pickle(par.valid_data_info_path)\n",
    "\n",
    "train_sampler = SortedRandomBatchSampler(train_df, par.batch_size, drop_last=True)\n",
    "train_dataset = ImageSequenceDataset(train_df, par.resize_mode, (par.img_w, par.img_h), par.img_means, par.img_stds, par.minus_point_5)\n",
    "train_dl = DataLoader(train_dataset, batch_sampler=train_sampler, num_workers=par.n_processors, pin_memory=par.pin_mem)\n",
    "\n",
    "valid_sampler = SortedRandomBatchSampler(valid_df, par.batch_size, drop_last=True)\n",
    "valid_dataset = ImageSequenceDataset(valid_df, par.resize_mode, (par.img_w, par.img_h), par.img_means, par.img_stds, par.minus_point_5)\n",
    "valid_dl = DataLoader(valid_dataset, batch_sampler=valid_sampler, num_workers=par.n_processors, pin_memory=par.pin_mem)\n",
    "\n",
    "print('Number of samples in training dataset: ', len(train_df.index))\n",
    "print('Number of samples in validation dataset: ', len(valid_df.index))\n",
    "print('='*50)\n",
    "\n",
    "\n",
    "# Model\n",
    "M_deepvo = DeepVO(par.img_h, par.img_w, par.batch_norm)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('CUDA used.')\n",
    "    M_deepvo = M_deepvo.cuda()\n",
    "\n",
    "\n",
    "# Load FlowNet weights pretrained with FlyingChairs\n",
    "# NOTE: the pretrained model assumes image rgb values in range [-0.5, 0.5]\n",
    "if par.pretrained_flownet and not par.resume:\n",
    "    if use_cuda:\n",
    "        pretrained_w = torch.load(par.pretrained_flownet)\n",
    "    else:\n",
    "        pretrained_w = torch.load(par.pretrained_flownet_flownet, map_location='cpu')\n",
    "    print('Load FlowNet pretrained model')\n",
    "    # Use only conv-layer-part of FlowNet as CNN for DeepVO\n",
    "    model_dict = M_deepvo.state_dict()\n",
    "    update_dict = {k: v for k, v in pretrained_w['state_dict'].items() if k in model_dict}\n",
    "    model_dict.update(update_dict)\n",
    "    M_deepvo.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "# Create optimizer\n",
    "if par.optim['opt'] == 'Adam':\n",
    "    optimizer = torch.optim.Adam(M_deepvo.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "elif par.optim['opt'] == 'Adagrad':\n",
    "    optimizer = torch.optim.Adagrad(M_deepvo.parameters(), lr=par.optim['lr'])\n",
    "elif par.optim['opt'] == 'Cosine':\n",
    "    optimizer = torch.optim.SGD(M_deepvo.parameters(), lr=par.optim['lr'])\n",
    "    T_iter = par.optim['T']*len(train_dl)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_iter, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Load trained DeepVO model and optimizer\n",
    "if par.resume:\n",
    "    M_deepvo.load_state_dict(torch.load(par.load_model_path))\n",
    "    optimizer.load_state_dict(torch.load(par.load_optimizer_path))\n",
    "    print('Load model from: ', par.load_model_path)\n",
    "    print('Load optimizer from: ', par.load_optimizer_path)\n",
    "\n",
    "\n",
    "# Train\n",
    "print('Record loss in: ', par.record_path)\n",
    "min_loss_t = 1e10\n",
    "min_loss_v = 1e10\n",
    "M_deepvo.train()\n",
    "for ep in range(par.epochs):\n",
    "    st_t = time.time()\n",
    "    print('='*50)\n",
    "    # Train\n",
    "    M_deepvo.train()\n",
    "    loss_mean = 0\n",
    "    t_loss_list = []\n",
    "    for _, t_x, t_y in train_dl:\n",
    "        if use_cuda:\n",
    "            t_x = t_x.cuda(non_blocking=par.pin_mem)\n",
    "            t_y = t_y.cuda(non_blocking=par.pin_mem)\n",
    "        ls = M_deepvo.step(t_x, t_y, optimizer).data.cpu().numpy()\n",
    "        t_loss_list.append(float(ls))\n",
    "        loss_mean += float(ls)\n",
    "        if par.optim == 'Cosine':\n",
    "            lr_scheduler.step()\n",
    "    print('Train take {:.1f} sec'.format(time.time()-st_t))\n",
    "    loss_mean /= len(train_dl)\n",
    "\n",
    "    # Validation\n",
    "    st_t = time.time()\n",
    "    M_deepvo.eval()\n",
    "    loss_mean_valid = 0\n",
    "    v_loss_list = []\n",
    "    for _, v_x, v_y in valid_dl:\n",
    "        if use_cuda:\n",
    "            v_x = v_x.cuda(non_blocking=par.pin_mem)\n",
    "            v_y = v_y.cuda(non_blocking=par.pin_mem)\n",
    "        v_ls = M_deepvo.get_loss(v_x, v_y).data.cpu().numpy()\n",
    "        v_loss_list.append(float(v_ls))\n",
    "        loss_mean_valid += float(v_ls)\n",
    "    print('Valid take {:.1f} sec'.format(time.time()-st_t))\n",
    "    loss_mean_valid /= len(valid_dl)\n",
    "\n",
    "\n",
    "    f = open(par.record_path, 'a')\n",
    "    f.write('Epoch {}\\ntrain loss mean: {}, std: {:.2f}\\nvalid loss mean: {}, std: {:.2f}\\n'.format(ep+1, loss_mean, np.std(t_loss_list), loss_mean_valid, np.std(v_loss_list)))\n",
    "    print('Epoch {}\\ntrain loss mean: {}, std: {:.2f}\\nvalid loss mean: {}, std: {:.2f}\\n'.format(ep+1, loss_mean, np.std(t_loss_list), loss_mean_valid, np.std(v_loss_list)))\n",
    "\n",
    "    # Save model\n",
    "    # save if the valid loss decrease\n",
    "    check_interval = 1\n",
    "    if loss_mean_valid < min_loss_v and ep % check_interval == 0:\n",
    "        min_loss_v = loss_mean_valid\n",
    "        print('Save model at ep {}, mean of valid loss: {}'.format(ep+1, loss_mean_valid))  # use 4.6 sec\n",
    "        torch.save(M_deepvo.state_dict(), par.save_model_path+'.valid')\n",
    "        torch.save(optimizer.state_dict(), par.save_optimzer_path+'.valid')\n",
    "    # save if the training loss decrease\n",
    "    check_interval = 1\n",
    "    if loss_mean < min_loss_t and ep % check_interval == 0:\n",
    "        min_loss_t = loss_mean\n",
    "        print('Save model at ep {}, mean of train loss: {}'.format(ep+1, loss_mean))\n",
    "        torch.save(M_deepvo.state_dict(), par.save_model_path+'.train')\n",
    "        torch.save(optimizer.state_dict(), par.save_optimzer_path+'.train')\n",
    "    f.close()\n",
    "    print(\"fin\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
